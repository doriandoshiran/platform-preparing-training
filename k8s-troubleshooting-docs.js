// Kubernetes troubleshooting documentation files
var k8sTroubleshootingDocs = {
    '/root/.easter_eggs': '# Kubernetes Easter Eggs Collection\n# =================================\n# You found the secret easter egg file!\n\nüé≠ Container Jokes:\n"Why did the container break up with the VM?\nBecause it was too heavyweight for the relationship!"\n\nüê≥ Docker Wisdom:\n"Life is like a Dockerfile - you layer your experiences!"\n\n‚ò∏Ô∏è  Kubernetes Philosophy:\n"In Kubernetes we trust, but we always verify the YAML!"\n\nüßÖ Shrek\'s Container Wisdom:\n"Containers are like onions - they have layers!\nAnd sometimes they make you cry when they crash!"\n\n# Hidden flag for the curious explorer\nHIDDEN_FLAG{EASTER_EGG_HUNTER}\n\n# Pro Tips:\n# - Always check hidden files (files starting with .)\n# - The best secrets are often in plain sight\n# - "Better out than in!" applies to logs too\n\nüéâ Congratulations on finding this secret file!\nKeep exploring for more hidden surprises!',
    
    '/root/troubleshooting/investigation-notes.txt': 'Kubernetes Cluster Investigation Notes\n=====================================\nIssues Identified:\n1. webapp-deployment pod in CrashLoopBackOff state\n   - Container exits with code 1\n   - Check logs for database connection issues\n   - Status: More crashed than Shrek\'s morning routine\n\n2. database-pv-claim stuck in Pending status\n   - StorageClass "fast-ssd" not found\n   - Check storage configuration\n   - Status: More pending than Fiona waiting for rescue\n\n3. nginx-service connectivity problems\n   - Service selector may be misconfigured\n   - Check service and deployment labels\n   - Status: More confused than Donkey in the morning\n\nCommands to investigate:\n- kubectl get pods\n- kubectl describe pod webapp-deployment-7d4b8c9f4d-xyz123\n- kubectl logs webapp-deployment-7d4b8c9f4d-xyz123\n- kubectl get pvc\n- kubectl describe pvc database-pv-claim\n- kubectl get services\n- kubectl describe service nginx-service\n\nLook for FLAGS in the output!\nüí° Pro tip: Debugging Kubernetes is like peeling an onion - lots of layers and it might make you cry!\nüîç Remember: Stay persistent - investigate thoroughly!',

    '/root/troubleshooting/meme-logs.txt': 'üé≠ Kubernetes Meme Logs & Fun Facts\n=====================================\n\nWhy did the pod crash?\nBecause it couldn\'t find its database... much like Shrek looking for his swamp! üßÖ\n\nKubernetes Facts:\n- "kubectl" is pronounced "kube-control" or "kube-cuttle" (debate continues)\n- A cluster without nodes is like Shrek without his swamp - pretty useless\n- CrashLoopBackOff is basically Kubernetes having a tantrum\n- "It works on my machine" doesn\'t apply in Kubernetes... it\'s "It works in my namespace"\n\nPro Tips:\n1. Always check the logs (they\'re like onions, full of layers)\n2. When in doubt, describe everything: kubectl describe all-the-things\n3. Remember: Debugging is like being a detective, but the criminal is your own code\n\nüîç Happy hunting for those flags! üö©\n\n# Hidden bonus for reading meme logs\nHIDDEN_FLAG{MEME_MASTER_LEVEL_UNLOCKED}',

    '/root/troubleshooting/incident-report.txt': 'Kubernetes Cluster Incident Report\n==================================\nDate: June 16, 2025\nReported by: Senior DevOps Engineer\nSeverity: HIGH - Production Impact\n\nINCIDENT SUMMARY:\nMultiple application pods failing to start due to various infrastructure issues.\nCustomer-facing services are degraded.\n\nAFFECTED SERVICES:\n1. webapp-deployment-7d4b8c9f4d-xyz123 - CrashLoopBackOff\n2. database-pv-claim - Stuck in Pending status\n3. nginx-service - LoadBalancer not functioning\n\nROOT CAUSE ANALYSIS:\n===================\n\nIssue #1: Application Container Failures\n- Symptoms: webapp pods crash immediately after start\n- Root Cause: Database connectivity problems\n- Investigation: Check network policies, service discovery\n- Status: INVESTIGATING\n\nIssue #2: Storage Provisioning Failure\n- Symptoms: PVC stuck in Pending state\n- Root Cause: Missing StorageClass "fast-ssd"\n- Investigation: Storage configuration needs review\n- Status: IDENTIFIED - Need to create proper StorageClass\n\nIssue #3: Load Balancer Service Issues\n- Symptoms: External IP remains <pending>\n- Root Cause: Service selector misconfiguration\n- Investigation: Label mismatch between service and pods\n- Status: IDENTIFIED - Service selector points to wrong labels\n\nHIDDEN INVESTIGATION NOTES:\n===========================\n# Engineers often hide debugging info in incident reports\n# HIDDEN_FLAG{INCIDENT_INVESTIGATION_COMPLETE}\n\n# The real issue is always in the details...\n# Check the service selectors carefully!\n# Storage classes are the key to persistent volume issues\n# Network policies might be blocking legitimate traffic\n\nRemember: "In production, every second counts!"\nStatus: ACTIVE INVESTIGATION',

    '/root/troubleshooting/debug-commands.txt': 'Kubernetes Debugging Command Reference\n=====================================\n\nBASIC CLUSTER INSPECTION:\nkubectl cluster-info\nkubectl get nodes -o wide\nkubectl get namespaces\nkubectl get all --all-namespaces\n\nPOD TROUBLESHOOTING:\nkubectl get pods --all-namespaces\nkubectl describe pod <pod-name>\nkubectl logs <pod-name>\nkubectl logs <pod-name> --previous\nkubectl exec -it <pod-name> -- /bin/bash\n\nSERVICE DEBUGGING:\nkubectl get services\nkubectl describe service <service-name>\nkubectl get endpoints <service-name>\n\nSTORAGE TROUBLESHOOTING:\nkubectl get pv\nkubectl get pvc\nkubectl describe pvc <pvc-name>\nkubectl get storageclass\n\nEVENT ANALYSIS:\nkubectl get events --sort-by=.metadata.creationTimestamp\nkubectl get events --field-selector involvedObject.name=<resource-name>\n\n# Pro tip: Always check events first!\n# They usually tell you exactly what\'s wrong\n# "Events are the breadcrumbs of Kubernetes debugging"\n\n# HIDDEN_FLAG{KUBECTL_MASTER_DEBUGGER}',

    '/root/troubleshooting/network-analysis.txt': 'Kubernetes Network Troubleshooting Guide\n========================================\n\nNETWORK COMPONENTS:\n==================\n1. Pod Network (CNI) - Calico/Flannel\n2. Service Network - ClusterIP/NodePort/LoadBalancer\n3. Ingress Controllers - External traffic routing\n4. Network Policies - Security rules\n\nCOMMON NETWORK ISSUES:\n=====================\n\nIssue: Pods can\'t communicate\n- Check: CNI plugin status\n- Debug: kubectl get pods -n kube-system\n- Fix: Restart network pods\n\nIssue: Service not reachable\n- Check: Service endpoints\n- Debug: kubectl get endpoints <service>\n- Fix: Verify pod labels match service selector\n\nWEBAPP CONNECTIVITY ISSUE:\n==========================\nCurrent Status: webapp cannot reach database\n\nInvestigation steps:\n1. Verify database pod is running ‚úì\n2. Check database service exists ‚úì\n3. Test service endpoint connectivity ‚úó\n4. Verify network policies\n5. Check service selector labels\n\nFindings:\n- Database pod: RUNNING (healthy)\n- Database service: EXISTS\n- Webapp pod: CrashLoopBackOff\n- Network policy: NEEDS INVESTIGATION\n\n# The issue is likely in service configuration\n# Check if service selector matches pod labels!\n\n# HIDDEN_FLAG{NETWORK_DEBUGGING_EXPERT}',

    '/root/cluster-info.txt': 'Kubernetes Cluster Information\n=============================\nCluster Name: production-cluster\nMaster Node: k8s-master-01.company.local\nVersion: v1.24.0\nContainer Runtime: Docker 20.10.17\nNetwork Plugin: Calico\nStorage: Local + NFS\n\nNODE INFORMATION:\n================\nMaster: k8s-master-01 (192.168.1.10)\n  Role: control-plane,master\n  Status: Ready\n  CPU: 4 cores\n  Memory: 8GB\n\nWorker: k8s-worker-01 (192.168.1.11)\n  Role: worker\n  Status: Ready\n  CPU: 8 cores\n  Memory: 16GB\n\nWorker: k8s-worker-02 (192.168.1.12)\n  Role: worker\n  Status: Ready\n  CPU: 8 cores\n  Memory: 16GB\n\nCLUSTER HEALTH:\n==============\n‚úÖ API Server: Healthy\n‚úÖ etcd: Healthy\n‚úÖ Controller Manager: Healthy\n‚úÖ Scheduler: Healthy\n‚ö†Ô∏è  Storage: Issues detected\n‚ö†Ô∏è  Networking: Partial issues\n\nKNOWN ISSUES:\n============\n1. StorageClass "fast-ssd" missing\n2. Service selector misconfigurations\n3. Network policy conflicts\n4. PVC provisioning failures\n\n# For emergency cluster access:\n# kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes\n\n# Remember: "With great power comes great responsibility"\n# This is a production cluster - be careful!',

    '/root/kubernetes-cheat-sheet.txt': 'Kubernetes Quick Reference\n=========================\n\nRESOURCE SHORTCUTS:\n==================\npo = pods\nsvc = services\ndeploy = deployments\nrs = replicasets\nns = namespaces\npv = persistentvolumes\npvc = persistentvolumeclaims\ncm = configmaps\nsa = serviceaccounts\ning = ingress\n\nQUICK COMMANDS:\n==============\n# Get everything\nkubectl get all\n\n# Watch pods\nkubectl get pods -w\n\n# Describe with events\nkubectl describe pod <n>\n\n# Quick logs\nkubectl logs -f <pod>\n\n# Emergency debug\nkubectl run debug --image=busybox -it --rm -- /bin/sh\n\nTROUBLESHOOTING FLOW:\n====================\n1. Check pod status\n2. Describe pod for events\n3. Check logs for errors\n4. Verify service configuration\n5. Test network connectivity\n6. Check resource constraints\n7. Review security policies\n\nPRODUCTION SAFETY:\n=================\n- Always backup before changes\n- Use --dry-run=client first\n- Test in staging environment\n- Have rollback plan ready\n- Monitor after changes\n\n# Emergency contacts:\n# DevOps Team: devops@company.local\n# Platform Team: platform@company.local\n# On-call: +1-555-KUBE-911\n\n# HIDDEN_FLAG{KUBERNETES_REFERENCE_MASTER}\n\n"May the YAML be with you!"'
};
